import pkg from 'pg';
const { Client } = pkg;
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration de connexion PostgreSQL Supabase
const connectionString = 'postgresql://postgres:LdTf7E6C8RxUgSdj@db.oowoybqlxlfcuddjxnkb.supabase.co:5432/postgres';

async function executeMigration() {
    console.log('ğŸš€ Connexion Ã  la base de donnÃ©es Supabase...\n');

    const client = new Client({
        connectionString,
        ssl: {
            rejectUnauthorized: false
        }
    });

    try {
        await client.connect();
        console.log('âœ… ConnectÃ© Ã  PostgreSQL!\n');

        // Lire le fichier SQL
        const sqlPath = path.join(__dirname, 'supabase', 'migrations', 'CONSOLIDATED_MIGRATION_PHASE1.sql');
        const sqlContent = fs.readFileSync(sqlPath, 'utf8');

        console.log('ğŸ“„ Fichier SQL chargÃ©');
        console.log('ğŸ“ Taille:', sqlContent.length, 'caractÃ¨res\n');

        console.log('âš¡ ExÃ©cution des migrations (commande par commande)...\n');

        // Diviser le SQL en commandes individuelles
        const commands = sqlContent
            .split(';')
            .map(cmd => cmd.trim())
            .filter(cmd => cmd.length > 0 && !cmd.startsWith('--') && !cmd.startsWith('/*'));

        let successCount = 0;
        let skipCount = 0;
        let errorCount = 0;

        for (let i = 0; i < commands.length; i++) {
            const command = commands[i] + ';';

            try {
                await client.query(command);
                successCount++;
                process.stdout.write('âœ…');
            } catch (error) {
                // Ignorer les erreurs "already exists" et "duplicate"
                if (error.message.includes('already exists') ||
                    error.message.includes('duplicate') ||
                    error.message.includes('does not exist')) {
                    skipCount++;
                    process.stdout.write('â­ï¸ ');
                } else {
                    errorCount++;
                    console.log(`\nâŒ Erreur commande ${i + 1}:`, error.message.substring(0, 150));
                }
            }

            // Pause courte pour Ã©viter de surcharger
            if (i % 10 === 0) {
                await new Promise(resolve => setTimeout(resolve, 100));
            }
        }

        console.log('\n\n' + '='.repeat(60));
        console.log('ğŸ“Š RÃ‰SUMÃ‰ DE L\'EXÃ‰CUTION');
        console.log('='.repeat(60));
        console.log(`âœ… SuccÃ¨s: ${successCount} commandes`);
        console.log(`â­ï¸  IgnorÃ©es (dÃ©jÃ  existantes): ${skipCount} commandes`);
        console.log(`âŒ Erreurs: ${errorCount} commandes`);
        console.log('='.repeat(60) + '\n');

        // VÃ©rifier les tables crÃ©Ã©es
        console.log('ğŸ” VÃ©rification des tables crÃ©Ã©es...\n');

        const result = await client.query(`
      SELECT tablename 
      FROM pg_tables 
      WHERE schemaname = 'public' 
      AND tablename IN ('projects', 'project_milestones', 'project_deliverables', 'invoices', 'invoice_items', 'payments', 'notifications')
      ORDER BY tablename;
    `);

        console.log(`âœ… ${result.rows.length}/7 tables crÃ©Ã©es:`);
        result.rows.forEach(row => {
            console.log(`   âœ“ ${row.tablename}`);
        });

        if (result.rows.length === 7) {
            console.log('\nğŸ‰ Migration Phase 1 terminÃ©e avec succÃ¨s!\n');
        } else {
            console.log('\nâš ï¸  Certaines tables manquent. VÃ©rifiez les erreurs ci-dessus.\n');
        }

    } catch (error) {
        console.error('\nâŒ ERREUR FATALE:', error.message);
        console.error('\nDÃ©tails:', error.stack);
    } finally {
        await client.end();
        console.log('ğŸ”Œ Connexion fermÃ©e.\n');
    }
}

executeMigration();
